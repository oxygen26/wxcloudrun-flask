{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'errcode': 0, 'errmsg': 'ok', 'next_cursor': '4gw7MepFLfgF2VC5not', \n",
    "'msg_list': [\n",
    "    {'msgid': 'BHhSzcRuYLqn3ndhgGccjSHvvq', 'open_kfid': 'wkoi51FQAAZWQojl_Wqez2Z6EidviCew', 'external_userid': 'wmoi51FQAAbhZmCxpjsQuHgzQKzwUyMg', 'send_time': 1716441434, 'origin': 3, 'msgtype': 'text', 'text': {'content': '的'}}, \n",
    "    {'msgid': 'A1Y8DYLtttUNSqh7CcMY5cmM5p', 'open_kfid': 'wkoi51FQAAZWQojl_Wqez2Z6EidviCew', 'external_userid': 'wmoi51FQAAbhZmCxpjsQuHgzQKzwUyMg', 'send_time': 1716442669, 'origin': 3, 'msgtype': 'text', 'text': {'content': '的'}}, \n",
    "    {'msgid': 'AvNxKaRuSdZqYDHkhYUyUPhB8y', 'open_kfid': 'wkoi51FQAAZWQojl_Wqez2Z6EidviCew', 'external_userid': 'wmoi51FQAAbhZmCxpjsQuHgzQKzwUyMg', 'send_time': 1716443224, 'origin': 3, 'msgtype': 'text', 'text': {'content': '1'}}\n",
    "    ], 'has_more': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "vc = requests.post('https://qyapi.weixin.qq.com/cgi-bin/kf/sync_msg?access_token=9hivAcqC_EE--o7z6qibWKRJOIKDE98vu-g8SL-FCT8rq6F9vC9yZlDbrWgQQ0h6LOqRRpum-RKM1X3EDOQZvZWRO59ap3LKqGMW15xxg2xvobfBZOFYOdK6WUkCbkyfaGi9wlzjxveYnpPrp3vGaX5U8t0EnTJt__TZa-p6rjOoaRaw2o900IvgAGtcF_R_UxH6s1XcYSx4BqPW8E7usw',\n",
    "\n",
    "\n",
    "\n",
    "json={\n",
    "    \"cursor\": \"\",\n",
    "    \"token\": \"ENCE5s7TFWRWL8UCyFjCThT4WBfeB6QWWZgt6uaBwfRNHrG\",\n",
    "    \"limit\": 1000,\n",
    "    \"voice_format\": 0,\n",
    "    \"open_kfid\": \"wkoi51FQAAZWQojl_Wqez2Z6EidviCew\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from werobot.messages.messages import TextMessage\n",
    "a = TextMessage(message={'d':'1'})\n",
    "a.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query engine error:: name 'commit_sctx' is not defined\n",
      "simple engine error:: name 'messages' is not defined\n"
     ]
    }
   ],
   "source": [
    "# # insertion =======================================================\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core.chat_engine import ContextChatEngine\n",
    "import sys,os\n",
    "#sys.path.append('/home/oxygen26/llama/python/')\n",
    "#from core import llm_y\n",
    "# * settings ==========================================================\n",
    "from llama_index.core import Settings\n",
    "\n",
    "from langchain.llms import QianfanLLMEndpoint\n",
    "from llama_index.llms.langchain.base import LangChainLLM\n",
    "#from llama_index.llms.openai import OpenAI\n",
    "\n",
    "#llm_openai = OpenAI(api_key=\"sk-6zm8Aqt9A31MPRiDV7WJ17EhfsMNjwwApt8PLkmuLZCH8kdo\",api_base=\"https://api.openai-proxy.org/v1\",model='gpt-4')\n",
    "\n",
    "\"\"\"For basic init and call\"\"\"\n",
    "\n",
    "# 'Yi-34B-Chat','ERNIE-Bot-4','ERNIE-Speed-128k','ERNIE-Bot-turbo'\n",
    "os.environ[\"QIANFAN_AK\"] = \"2kFfoTXEOjItYtBAQtVZUv17\" #\"Q0gXTGHI4oM17zMbI3sMeqIg\"#\n",
    "os.environ[\"QIANFAN_SK\"] = \"s38GyXy4v8xipic8rIlVkm0gTeBL4zkU\" #\"iWmqKV7A1WSVwatdbmOxK4L5Av1Goxqf\"#\n",
    "\n",
    "qllm_y = QianfanLLMEndpoint(model='Yi-34B-Chat',#'Yi-34B-Chat','ERNIE-Bot-4','ERNIE-Speed-128k','ERNIE-Bot-turbo'\n",
    "                           #streaming=True,\n",
    "                        ak=os.getenv('QIANFAN_AK'), sk=os.getenv('QIANFAN_SK'),**{'top_p': 0.8, 'temperature': 0.1, 'penalty_score': 1})\n",
    "#res = llm(\"hi\")\n",
    "qllm_wx = QianfanLLMEndpoint(model='ERNIE-Speed-128k',#'Yi-34B-Chat','ERNIE-Bot-4','ERNIE-Speed-128k','ERNIE-Bot-turbo'\n",
    "                           #streaming=True,\n",
    "                        ak=os.getenv('QIANFAN_AK'), sk=os.getenv('QIANFAN_SK'),**{'top_p': 0.8, 'temperature': 0.1, 'penalty_score': 1})\n",
    "qllm_wx4 = QianfanLLMEndpoint(model='ERNIE-4.0-8K',#'Yi-34B-Chat','ERNIE-Bot-4','ERNIE-Speed-128k','ERNIE-Bot-turbo'\n",
    "                           #streaming=True,\n",
    "                        ak=os.getenv('QIANFAN_AK'), sk=os.getenv('QIANFAN_SK'),**{'top_p': 0.8, 'temperature': 0.1, 'penalty_score': 1})\n",
    "#-----------------------------------------------------\n",
    "llm_y = LangChainLLM(llm=qllm_y)\n",
    "Settings.llm = llm_y\n",
    "\n",
    "# messages = [\n",
    "#     ChatMessage(\n",
    "#         #role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "#     ),\n",
    "#     ChatMessage(role=\"user\", content=\"hi\"),\n",
    "# ]\n",
    "\n",
    "#custom_chat_history = [ChatMessage(role= (MessageRole.USER if i['role']=='user' else MessageRole.ASSISTANT),content=i['content']) for i in session.messages]\n",
    "#for wenxin_model in ['Yi-34B-Chat','ERNIE-Bot-4','ERNIE-Speed-128k','ERNIE-Bot-turbo']:\n",
    "llama_flag=0\n",
    "try:\n",
    "                    \n",
    "    from llama_index.core.retrievers import QueryFusionRetriever\n",
    "    retriever = QueryFusionRetriever(\n",
    "        [commit_sctx.std_retriever(), commit_file_sctx.std_retriever()],\n",
    "        similarity_top_k=2,\n",
    "        num_queries=1,  # set this to 1 to disable query generation\n",
    "        use_async=False,#True,\n",
    "        verbose=True,\n",
    "        # query_gen_prompt=\"...\",  # we could override the query generation prompt here\n",
    "    )\n",
    "    # query_engine = RetrieverQueryEngine(node_postprocessors=[MetadataReplacementPostProcessor(target_metadata_key=\"window\")],\n",
    "    #             retriever=retriever,\n",
    "    #             response_synthesizer=synth\n",
    "    #             )#.query('生物信息学，给出参考链接')\n",
    "    chat_engine = ContextChatEngine.from_defaults(\n",
    "        retriever=retriever,#commit_sctx.query_engine(),\n",
    "    #condense_question_prompt=custom_prompt,\n",
    "        #chat_history=custom_chat_history[:-1],\n",
    "        #service_context=service_context,\n",
    "        verbose=True\n",
    "    )\n",
    "    response_text = {'result':chat_engine.chat(\n",
    "        messages#custom_chat_history[-1].content\n",
    "        ).response,\n",
    "                        \"usage\":{\"total_tokens\":2,\"completion_tokens\":1}}\n",
    "    #print(response.)\n",
    "    llama_flag=1\n",
    "    #break\n",
    "except Exception as e:\n",
    "    print('query engine error::',e)\n",
    "    #break\n",
    "    try:\n",
    "        from llama_index.core.chat_engine import SimpleChatEngine\n",
    "\n",
    "        chat_engine = SimpleChatEngine.from_defaults(\n",
    "            #chat_history=custom_chat_history[:-1],\n",
    "        #service_context=service_context,\n",
    "        verbose=False)\n",
    "        response_text = {'result':chat_engine.chat(\n",
    "            messages#custom_chat_history[-1].content\n",
    "            ).response,\"usage\":{\"total_tokens\":2,\"completion_tokens\":1}}\n",
    "        llama_flag=1\n",
    "        #break\n",
    "    except Exception as e:\n",
    "        print('simple engine error::',e)\n",
    "        #insertion =------------==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oxygen26/miniconda3/envs/MP/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "[INFO] [05-22 14:23:42] oauth.py:228 [t:140487284250432]: trying to refresh access_token for ak `2kFfoT***`\n",
      "[INFO] [05-22 14:23:43] oauth.py:243 [t:140487284250432]: sucessfully refresh access_token\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AgentChatResponse' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchat_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AgentChatResponse' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "chat_engine.chat('hi').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install qianfan llama-index-llms-langchain llama-index-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.12.25 server starting up (using AutoServer())...\n",
      "Listening on http://127.0.0.1:8888/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import werobot\n",
    "robot = werobot.WeRoBot(app_id='wx20b1396d77813bab',token='AAQ9G7sEAAABAAAAAAAZHBKxAjsPDrr0/hdLZiAAAAAraAdzKm8i8JwFJ68cDOJBtIHsmv3F8e00LCv7f+tYvrdcIYN+n7bDX7DzL30SBV0F41HP29O6/zzd24/PPjeAmEt1eV+92opWZoTZaYXE4803U3e+7eFwGqdjQCxZ5L6SFxz0e5v1XDMlpLF5mQd/oW6tQ3lCcFxS')\n",
    "robot.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 1, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/MP/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[65], line 2\u001b[0m\n    ET.fromstring(json_str)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/MP/lib/python3.8/xml/etree/ElementTree.py:1325\u001b[0;36m in \u001b[0;35mXML\u001b[0;36m\n\u001b[0;31m    parser.feed(text)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m not well-formed (invalid token): line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "json_str= b'{\\n\"ToUserName\": \"gh_058a3b90ed88\",\\n\"FromUserName\": \"o9tCG5t2oLbqD2oqAMoHygHhQT-A\",\\n\"CreateTime\": 1716270854,\\n\"MsgType\": \"text\",\\n\"Content\": \"opo\",\\n\"MsgId\": 24571088052194022\\n}\\n'\n",
    "ET.fromstring(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "syntax error: line 3, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/MP/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[75], line 1\u001b[0m\n    ET.fromstring(b'\\n\\n1716274957\\n\\n\\n24571148680158371\\n')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/MP/lib/python3.8/xml/etree/ElementTree.py:1325\u001b[0;36m in \u001b[0;35mXML\u001b[0;36m\n\u001b[0;31m    parser.feed(text)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m syntax error: line 3, column 0\n"
     ]
    }
   ],
   "source": [
    "ET.fromstring(b'\\n\\n1716274957\\n\\n\\n24571148680158371\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b'<xml><ToUserName>gh_058a3b90ed88</ToUserName><FromUserName>o9tCG5t2oLbqD2oqAMoHygHhQT-A</FromUserName><CreateTime>1716277382</CreateTime><MsgType>text</MsgType><Content>ggg</Content><MsgId>24571182724586606</MsgId></xml>'\n",
    "b'<xml><ToUserName><![CDATA[gh_058a3b90ed88]]></ToUserName>\\n<FromUserName><![CDATA[o9tCG5t2oLbqD2oqAMoHygHhQT-A]]></FromUserName>\\n<CreateTime>1716282717</CreateTime>\\n<MsgType><![CDATA[text]]></MsgType>\\n<Content><![CDATA[\\xe5\\x9b\\x9e\\xe5\\xa4\\x8d\\xe6\\x96\\x87\\xe5\\xad\\x97]]></Content>\\n<MsgId>24571260183525227</MsgId>\\n</xml>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if xmls.find('ToUserName'):\n",
    "    print(xmls.find('ToUserName').text)#.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     xml_str \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mtostring(root, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xml_str\n\u001b[0;32m---> 24\u001b[0m \u001b[43mjson_to_xml\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mToUserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgh_058a3b90ed88\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFromUserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo9tCG5t2oLbqD2oqAMoHygHhQT-A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCreateTime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1716270854\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMsgType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMsgId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24571088052194022\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "def json_to_xml(json_data):\n",
    "    # 创建 XML 根元素\n",
    "    root = ET.Element(\"xml\")\n",
    "    \n",
    "    # 递归转换 JSON 数据为 XML 元素\n",
    "    def build_xml_element(parent, data):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                child = ET.SubElement(parent, key)\n",
    "                build_xml_element(child, value)\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                child = ET.SubElement(parent, \"item\")\n",
    "                build_xml_element(child, item)\n",
    "        else:\n",
    "            parent.text = str(data)\n",
    "\n",
    "    build_xml_element(root, json_data)\n",
    "    \n",
    "    # 生成 XML 字符串\n",
    "    xml_str = ET.tostring(root, encoding='utf-8')\n",
    "    return xml_str\n",
    "\n",
    "json_to_xml(\n",
    "            {\"ToUserName\": \"gh_058a3b90ed88\",\n",
    "             \"FromUserName\": \"o9tCG5t2oLbqD2oqAMoHygHhQT-A\",\n",
    "             \"CreateTime\": 1716270854,\n",
    "             \"MsgType\": \"text\",\n",
    "             \"Content\": \"opo\",\n",
    "             \"MsgId\": 24571088052194022})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" ?>\n",
      "<xml>\n",
      "  <ToUserName>gh_058a3b90ed88</ToUserName>\n",
      "  <FromUserName>o9tCG5t2oLbqD2oqAMoHygHhQT-A</FromUserName>\n",
      "  <CreateTime>1716270854</CreateTime>\n",
      "  <MsgType>text</MsgType>\n",
      "  <Content>opo</Content>\n",
      "  <MsgId>24571088052194022</MsgId>\n",
      "</xml>\n",
      "\n",
      "Parsed XML - ToUserName: %s, FromUserName: %s, MsgType: %s, Content: %s gh_058a3b90ed88 o9tCG5t2oLbqD2oqAMoHygHhQT-A text opo\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import xml\n",
    "import json\n",
    "json_str= b'{\\n\"ToUserName\": \"gh_058a3b90ed88\",\\n\"FromUserName\": \"o9tCG5t2oLbqD2oqAMoHygHhQT-A\",\\n\"CreateTime\": 1716270854,\\n\"MsgType\": \"text\",\\n\"Content\": \"opo\",\\n\"MsgId\": 24571088052194022\\n}\\n'\n",
    "data = json.loads(json_str)\n",
    "\n",
    "# 创建 XML 元素\n",
    "root = ET.Element(\"xml\")\n",
    "\n",
    "for key, value in data.items():\n",
    "    element = ET.SubElement(root, key)\n",
    "    element.text = str(value)\n",
    "\n",
    "# 生成 XML 字符串\n",
    "xml_str = ET.tostring(root, encoding='utf-8')\n",
    "xmls = ET.fromstring(xml_str)\n",
    "# 格式化 XML 字符串以便更好地阅读\n",
    "dom = xml.dom.minidom.parseString(xml_str)\n",
    "pretty_xml_str = dom.toprettyxml(indent=\"  \")\n",
    "\n",
    "print(pretty_xml_str)\n",
    "ToUserName = xmls.find('ToUserName').text\n",
    "FromUserName = xmls.find('FromUserName').text\n",
    "MsgType = xmls.find('MsgType').text\n",
    "Content = xmls.find('Content').text if MsgType == 'text' else ''\n",
    "\n",
    "print('Parsed XML - ToUserName: %s, FromUserName: %s, MsgType: %s, Content: %s', ToUserName, FromUserName, MsgType, Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <xml>\n",
      "      <ToUserName><![CDATA[toUser]]></ToUserName>\n",
      "      <FromUserName><![CDATA[fromUser]]></FromUserName>\n",
      "      <CreateTime>12345678</CreateTime>\n",
      "      <MsgType><![CDATA[text]]></MsgType>\n",
      "      <Content><![CDATA[你好]]></Content>\n",
      "    </xml>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def generate_reply(to_user, from_user, content):\n",
    "    # 生成回复消息的 XML 格式\n",
    "    reply_xml = \"\"\"\n",
    "    <xml>\n",
    "      <ToUserName><![CDATA[{0}]]></ToUserName>\n",
    "      <FromUserName><![CDATA[{1}]]></FromUserName>\n",
    "      <CreateTime>{2}</CreateTime>\n",
    "      <MsgType><![CDATA[text]]></MsgType>\n",
    "      <Content><![CDATA[{3}]]></Content>\n",
    "    </xml>\n",
    "    \"\"\".format(to_user, from_user, 12345678, content)\n",
    "    return reply_xml\n",
    "a = generate_reply('toUser','fromUser','你好')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from werobot.contrib.flask import make_view\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.add_url_rule(rule='/robot/', # WeRoBot 的绑定地址\n",
    "                endpoint='werobot', # Flask 的 endpoint\n",
    "                view_func=make_view(robot),\n",
    "                methods=['GET', 'POST'])\n",
    "\n",
    "#app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
